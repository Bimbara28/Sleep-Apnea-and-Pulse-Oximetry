{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e3c2c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "from typing import Tuple\n",
    "\n",
    "lucky_7 = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613afffc",
   "metadata": {},
   "source": [
    "#### 1. `ahi_o0h3`\n",
    "\n",
    "* Counts **obstructive apneas** with **no oxygen desaturation threshold**, with or without arousal.\n",
    "* Counts **hypopneas** that have both:\n",
    "\n",
    "  * \\> 30% flow reduction for mare than $n$ $seconds$ (say $10s$)\n",
    "  * **AND** ≥3% oxygen desaturation\n",
    "  * With or without arousal.\n",
    "* The formula:\n",
    "\n",
    "  $\\text{AHI} = \\frac{\\text{(n obstructive apneas) + (n hypopneas meeting criteria)}}{\\text{hours of sleep}}$\n",
    "\n",
    "#### 2. `ahi_o0h3a`\n",
    "\n",
    "* Counts **obstructive apneas** same as above.\n",
    "* Counts **hypopneas** that have:\n",
    "\n",
    "  * \\> 30% flow reduction for mare than $n$ $seconds$ (say $10s$)\n",
    "  * **AND** either:\n",
    "\n",
    "    * ≥3% oxygen desaturation **OR**\n",
    "    * Presence of arousal\n",
    "* So this is a bit broader in the hypopnea count because it includes events with desaturation **or** arousal (not necessarily both).\n",
    "\n",
    "`≥3% oxygen desaturation`: this means the blood oxygen saturation (SpO₂) level drops by 3% or more from the baseline during a breathing event (like hypopnea or apnea).\n",
    "\n",
    "`> 30% flow reduction`: It refers to a partial blockage of the airway, leading to a reduction in airflow (but not a complete stop like in apnea). Specifically: the person’s breathing is reduced by at least 30% of normal baseline airflow. This is measured using nasal pressure sensors or thermal airflow sensors in polysomnography (PSG).\n",
    "\n",
    "`Arousal`: An arousal is a brief awakening or change in brain activity during sleep, detected by EEG.\n",
    "\n",
    "#### Key difference:\n",
    "\n",
    "* `ahi_o0h3`: Hypopneas require **both ≥3% desaturation AND with/without arousal**.\n",
    "* `ahi_o0h3a`: Hypopneas require **≥3% desaturation OR arousal** (more inclusive).\n",
    "\n",
    "#### What does this mean for your model?\n",
    "\n",
    "* Since you’re working with only **SpO₂ (oxygen saturation) signals**, you can detect events related to **desaturation** but **not arousals** (which require EEG).\n",
    "* So **`ahi_o0h3` aligns better** with your data, since it strictly requires ≥3% desaturation in hypopneas.\n",
    "* Using **`ahi_o0h3a` might overestimate hypopneas** in your dataset because it counts events with arousal but no desaturation, which you can’t detect with SpO₂ alone.\n",
    "\n",
    "#### Summary for your use case:\n",
    "\n",
    "| AHI Variable | Includes hypopneas with desaturation only? | Includes hypopneas with arousal only? | Suitable for SpO₂-only models? |\n",
    "| ------------ | ------------------------------------------ | ------------------------------------- | ------------------------------ |\n",
    "|**`ahi_o0h3`**| **Yes**                                    | **No**                                | **Yes**                        |\n",
    "| `ahi_o0h3a`  | Yes                                        | Yes                                   | No                             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb945e9",
   "metadata": {},
   "source": [
    "So, Based on the above logic let's choose `ahi_o0h3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f5b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.act = nn.LeakyReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Optional 1x1 conv if channel sizes mismatch in skip\n",
    "        self.skip = nn.Conv1d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.act(out)\n",
    "        out = self.pool(out)\n",
    "\n",
    "        # Adjust skip path if necessary\n",
    "        skip = self.skip(x)\n",
    "        skip = self.pool(skip)  # apply same pooling\n",
    "        return out + skip\n",
    "\n",
    "\n",
    "class DilatedBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                              padding=dilation, dilation=dilation)\n",
    "        self.act = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.conv(x))\n",
    "\n",
    "\n",
    "class OxiNetCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.window_size = 3600\n",
    "        self.num_windows = 7\n",
    "\n",
    "        # Local CNN blocks for each window: 1 -> 4 -> 8 channels\n",
    "        self.block1 = ConvBlock(1, 4)\n",
    "        self.block2 = ConvBlock(4, 8)\n",
    "        self.block3 = ConvBlock(8, 8)\n",
    "\n",
    "        # Dilated blocks for temporal features (example: 2 blocks)\n",
    "        self.dilated1 = DilatedBlock(8, 8, dilation=2)\n",
    "        self.dilated2 = DilatedBlock(8, 8, dilation=4)\n",
    "\n",
    "        # Flatten + Fully Connected Layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(8 * 98, 1)  # final AHI score\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, 1, 25200)  ← 7 windows × 3600 samples\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        windows = x.unfold(dimension=2, size=self.window_size, step=self.window_size)  # shape: (B, 1, 7, 3600)\n",
    "        windows = windows.permute(0, 2, 1, 3)  # (B, 7, 1, 3600)\n",
    "\n",
    "        outputs = []\n",
    "        for i in range(self.num_windows):\n",
    "            w = windows[:, i]  # (B, 1, 3600)\n",
    "            out = self.block1(w)\n",
    "            out = self.block2(out)\n",
    "            out = self.block3(out)\n",
    "            outputs.append(out)\n",
    "\n",
    "        # Concatenate along time dimension\n",
    "        concat = torch.cat(outputs, dim=2)  # (B, 8, 7×225 = 1575)\n",
    "\n",
    "        # Dilated blocks\n",
    "        out = self.dilated1(concat)  # (B, 8, ~1575)\n",
    "        out = self.dilated2(out)     # (B, 8, ~1575)\n",
    "\n",
    "        # Downsample (if needed), then flatten\n",
    "        out = F.adaptive_avg_pool1d(out, 98)  # (B, 8, 98)\n",
    "        out = out.permute(0, 2, 1)            # (B, 98, 8)\n",
    "        out = self.flatten(out)              # (B, 98×8 = 784)\n",
    "\n",
    "        out = self.fc(out)                   # (B, 1) → AHI prediction\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7801a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaNs in batch_tensor? tensor(False)\n",
      "torch.Size([16, 1, 25200])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to your data folder\n",
    "base_path = \"data/shhs/polysomnography/edfs/shhs1\"\n",
    "\n",
    "# Prepare a list to collect each patient's signal\n",
    "signals = []\n",
    "\n",
    "# Loop through file IDs 200001 to 200016\n",
    "for pid in range(200001, 200017):\n",
    "    file_path = os.path.join(base_path, f\"shhs1-{pid}_cleaned.parquet\")\n",
    "    \n",
    "    # Load the parquet file\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # FIX: Clean NaNs first!\n",
    "    df[\"SaO2\"] = df[\"SaO2\"].ffill().bfill()\n",
    "\n",
    "    # Now extract the signal (safe from NaNs)\n",
    "    spo2_signal = df[\"SaO2\"].values[:25200].astype(np.float32)\n",
    "\n",
    "    # Pad if needed\n",
    "    if len(spo2_signal) < 25200:\n",
    "        pad_len = 25200 - len(spo2_signal)\n",
    "        spo2_signal = np.pad(spo2_signal, (0, pad_len), mode='edge')\n",
    "\n",
    "    # Optional: Clip and normalize\n",
    "    spo2_signal = np.clip(spo2_signal, 0, 100)\n",
    "    spo2_signal = spo2_signal / 100.0\n",
    "\n",
    "    # Convert to torch tensor and add channel dim\n",
    "    tensor = torch.tensor(spo2_signal, dtype=torch.float32).unsqueeze(0)  # (1, 25200)\n",
    "    signals.append(tensor)\n",
    "\n",
    "# Final stack\n",
    "batch_tensor = torch.stack(signals)  # (16, 1, 25200)\n",
    "\n",
    "# ✅ Final check\n",
    "print(\"Any NaNs in batch_tensor?\", torch.isnan(batch_tensor).any())  # Should be: tensor(False)\n",
    "print(batch_tensor.shape)  # torch.Size([16, 1, 25200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "573d63f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eshan\\AppData\\Local\\Temp\\ipykernel_17192\\3347034700.py:1: DtypeWarning: Columns (1214) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  shhs1_dataset_df = pd.read_csv(\"shhs1-dataset-0.21.0.csv\")\n"
     ]
    }
   ],
   "source": [
    "shhs1_dataset_df = pd.read_csv(\"shhs1-dataset-0.21.0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e80cae43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nsrrid</th>\n",
       "      <th>pptid</th>\n",
       "      <th>ecgdate</th>\n",
       "      <th>lvh3_1</th>\n",
       "      <th>lvh3_3</th>\n",
       "      <th>st4_1_3</th>\n",
       "      <th>st5_1_3</th>\n",
       "      <th>lvhst</th>\n",
       "      <th>mob1</th>\n",
       "      <th>part2deg</th>\n",
       "      <th>...</th>\n",
       "      <th>eoglqual</th>\n",
       "      <th>chinqual</th>\n",
       "      <th>oximqual</th>\n",
       "      <th>posqual</th>\n",
       "      <th>lightoff</th>\n",
       "      <th>oximet51</th>\n",
       "      <th>monitor_id</th>\n",
       "      <th>headbox_id</th>\n",
       "      <th>rcrdtime</th>\n",
       "      <th>psg_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200001</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7:16:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200002</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200003</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7:10:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200004</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5:58:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200005</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7:57:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>205800</td>\n",
       "      <td>5835</td>\n",
       "      <td>-854.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7:20:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>205801</td>\n",
       "      <td>5836</td>\n",
       "      <td>-755.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7:00:00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5801</th>\n",
       "      <td>205802</td>\n",
       "      <td>5837</td>\n",
       "      <td>-768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7:30:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5802</th>\n",
       "      <td>205803</td>\n",
       "      <td>5838</td>\n",
       "      <td>-755.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8:09:00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5803</th>\n",
       "      <td>205804</td>\n",
       "      <td>5839</td>\n",
       "      <td>-713.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6:38:00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5804 rows × 1271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nsrrid  pptid  ecgdate  lvh3_1  lvh3_3  st4_1_3  st5_1_3  lvhst  mob1  \\\n",
       "0     200001      1      NaN     NaN     NaN      NaN      NaN    NaN   NaN   \n",
       "1     200002      2      NaN     NaN     NaN      NaN      NaN    NaN   NaN   \n",
       "2     200003      3      NaN     NaN     NaN      NaN      NaN    NaN   NaN   \n",
       "3     200004      4      NaN     NaN     NaN      NaN      NaN    NaN   NaN   \n",
       "4     200005      5      NaN     NaN     NaN      NaN      NaN    NaN   NaN   \n",
       "...      ...    ...      ...     ...     ...      ...      ...    ...   ...   \n",
       "5799  205800   5835   -854.0     0.0     0.0      0.0      0.0    0.0   0.0   \n",
       "5800  205801   5836   -755.0     0.0     0.0      0.0      0.0    0.0   0.0   \n",
       "5801  205802   5837   -768.0     0.0     0.0      0.0      0.0    0.0   0.0   \n",
       "5802  205803   5838   -755.0     0.0     0.0      0.0      0.0    0.0   0.0   \n",
       "5803  205804   5839   -713.0     0.0     0.0      0.0      0.0    0.0   0.0   \n",
       "\n",
       "      part2deg  ...  eoglqual  chinqual  oximqual  posqual  lightoff  \\\n",
       "0          NaN  ...         4         4         4        4       1.0   \n",
       "1          NaN  ...         2         2         4        4       NaN   \n",
       "2          NaN  ...         4         4         4        4       1.0   \n",
       "3          NaN  ...         3         3         3        3       0.0   \n",
       "4          NaN  ...         4         4         4        4       0.0   \n",
       "...        ...  ...       ...       ...       ...      ...       ...   \n",
       "5799       0.0  ...         4         4         4        4       0.0   \n",
       "5800       0.0  ...         4         4         4        4       1.0   \n",
       "5801       0.0  ...         4         3         4        4       0.0   \n",
       "5802       0.0  ...         4         4         4        4       0.0   \n",
       "5803       0.0  ...         4         2         4        4       1.0   \n",
       "\n",
       "      oximet51  monitor_id  headbox_id  rcrdtime  psg_month  \n",
       "0         96.0        18.0        18.0   7:16:00          6  \n",
       "1         94.0        17.0        17.0   9:00:00          1  \n",
       "2         95.0        17.0        17.0   7:10:00          2  \n",
       "3         96.0        19.0        19.0   5:58:00          4  \n",
       "4         96.0        18.0        18.0   7:57:00          3  \n",
       "...        ...         ...         ...       ...        ...  \n",
       "5799      94.0         6.0        60.0   7:20:00          1  \n",
       "5800      91.0        10.0        10.0   7:00:00         11  \n",
       "5801      95.0        10.0        10.0   7:30:00         10  \n",
       "5802      97.0         9.0         9.0   8:09:00         11  \n",
       "5803      91.0         8.0         8.0   6:38:00         11  \n",
       "\n",
       "[5804 rows x 1271 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shhs1_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb8eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppose batch_tensor is your input: shape (16, 1, 25200)\n",
    "# And you have corresponding AHI labels:\n",
    "ahi_labels_np = shhs1_dataset_df[(200000 < shhs1_dataset_df[\"nsrrid\"]) & (shhs1_dataset_df[\"nsrrid\"] < 200017)][\"ahi_o0h3\"].values.astype(np.float32)\n",
    "ahi_labels = torch.tensor(ahi_labels_np).unsqueeze(1)\n",
    "ahi_mean = ahi_labels.mean()\n",
    "ahi_std = ahi_labels.std()\n",
    "ahi_labels = (ahi_labels - ahi_mean) / ahi_std\n",
    "\n",
    "# Define model\n",
    "model = OxiNetCNN()\n",
    "\n",
    "# Loss function (regression)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "batch_tensor = batch_tensor.to(device)\n",
    "ahi_labels = ahi_labels.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d4c882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 114.87630462646484\n",
      "Epoch 10/1000, Loss: 22.216888427734375\n",
      "Epoch 20/1000, Loss: 8.067031860351562\n",
      "Epoch 30/1000, Loss: 3.2375457286834717\n",
      "Epoch 40/1000, Loss: 1.8465617895126343\n",
      "Epoch 50/1000, Loss: 1.4123653173446655\n",
      "Epoch 60/1000, Loss: 1.2663025856018066\n",
      "Epoch 70/1000, Loss: 1.1693907976150513\n",
      "Epoch 80/1000, Loss: 1.0929324626922607\n",
      "Epoch 90/1000, Loss: 1.0235098600387573\n",
      "Epoch 100/1000, Loss: 0.9588758945465088\n",
      "Epoch 110/1000, Loss: 0.8954384326934814\n",
      "Epoch 120/1000, Loss: 0.8285180926322937\n",
      "Epoch 130/1000, Loss: 0.755210280418396\n",
      "Epoch 140/1000, Loss: 0.6732851266860962\n",
      "Epoch 150/1000, Loss: 0.5817383527755737\n",
      "Epoch 160/1000, Loss: 0.4789332449436188\n",
      "Epoch 170/1000, Loss: 0.3678611218929291\n",
      "Epoch 180/1000, Loss: 0.25821220874786377\n",
      "Epoch 190/1000, Loss: 0.16505129635334015\n",
      "Epoch 200/1000, Loss: 0.09094049036502838\n",
      "Epoch 210/1000, Loss: 0.0439547523856163\n",
      "Epoch 220/1000, Loss: 0.02277567610144615\n",
      "Epoch 230/1000, Loss: 0.011699371039867401\n",
      "Epoch 240/1000, Loss: 0.005035707261413336\n",
      "Epoch 250/1000, Loss: 0.0020050618331879377\n",
      "Epoch 260/1000, Loss: 0.0007829480455256999\n",
      "Epoch 270/1000, Loss: 0.00025141186779364944\n",
      "Epoch 280/1000, Loss: 6.305696297204122e-05\n",
      "Epoch 290/1000, Loss: 1.7679396478342824e-05\n",
      "Epoch 300/1000, Loss: 6.440219294745475e-06\n",
      "Epoch 310/1000, Loss: 3.030489779121126e-06\n",
      "Epoch 320/1000, Loss: 1.4847925058347755e-06\n",
      "Epoch 330/1000, Loss: 6.302918222900189e-07\n",
      "Epoch 340/1000, Loss: 2.496712454558292e-07\n",
      "Epoch 350/1000, Loss: 7.832512238792333e-08\n",
      "Epoch 360/1000, Loss: 2.075437777193656e-08\n",
      "Epoch 370/1000, Loss: 5.699201999220804e-09\n",
      "Epoch 380/1000, Loss: 2.252481534625872e-09\n",
      "Epoch 390/1000, Loss: 1.0144178830273631e-09\n",
      "Epoch 400/1000, Loss: 5.104512368347969e-10\n",
      "Epoch 410/1000, Loss: 1.8909053489668537e-10\n",
      "Epoch 420/1000, Loss: 6.747404024398662e-11\n",
      "Epoch 430/1000, Loss: 3.151347238716795e-11\n",
      "Epoch 440/1000, Loss: 1.994761300583292e-11\n",
      "Epoch 450/1000, Loss: 1.8787651989704557e-11\n",
      "Epoch 460/1000, Loss: 3.441959217642676e-11\n",
      "Epoch 470/1000, Loss: 7.150637026942519e-11\n",
      "Epoch 480/1000, Loss: 3.5501393491621513e-11\n",
      "Epoch 490/1000, Loss: 5.0197193623979786e-11\n",
      "Epoch 500/1000, Loss: 1.887646983167457e-11\n",
      "Epoch 510/1000, Loss: 1.1543668798630335e-11\n",
      "Epoch 520/1000, Loss: 3.454139752001595e-12\n",
      "Epoch 530/1000, Loss: 7.269754243033333e-12\n",
      "Epoch 540/1000, Loss: 2.050817848875397e-12\n",
      "Epoch 550/1000, Loss: 9.068440443016357e-13\n",
      "Epoch 560/1000, Loss: 3.099881462631515e-13\n",
      "Epoch 570/1000, Loss: 4.2722769766356805e-13\n",
      "Epoch 580/1000, Loss: 3.297820350134373e-12\n",
      "Epoch 590/1000, Loss: 1.1839557112480747e-12\n",
      "Epoch 600/1000, Loss: 4.556494070939721e-13\n",
      "Epoch 610/1000, Loss: 7.505246424344136e-13\n",
      "Epoch 620/1000, Loss: 5.198522168292641e-12\n",
      "Epoch 630/1000, Loss: 5.914393974570942e-12\n",
      "Epoch 640/1000, Loss: 4.852031276758595e-11\n",
      "Epoch 650/1000, Loss: 2.2240889685498644e-11\n",
      "Epoch 660/1000, Loss: 3.1405114619964536e-11\n",
      "Epoch 670/1000, Loss: 6.860025048016638e-11\n",
      "Epoch 680/1000, Loss: 6.461765844623102e-11\n",
      "Epoch 690/1000, Loss: 9.193802663620687e-11\n",
      "Epoch 700/1000, Loss: 2.767831797090281e-11\n",
      "Epoch 710/1000, Loss: 6.356427884046667e-11\n",
      "Epoch 720/1000, Loss: 4.7202255992750963e-11\n",
      "Epoch 730/1000, Loss: 1.1852831216518922e-10\n",
      "Epoch 740/1000, Loss: 5.986057483031715e-11\n",
      "Epoch 750/1000, Loss: 1.6155091153713386e-11\n",
      "Epoch 760/1000, Loss: 4.1688444363252586e-11\n",
      "Epoch 770/1000, Loss: 1.1346493189456908e-11\n",
      "Epoch 780/1000, Loss: 4.667290165460969e-11\n",
      "Epoch 790/1000, Loss: 6.536550467561852e-11\n",
      "Epoch 800/1000, Loss: 5.862778318377337e-11\n",
      "Epoch 810/1000, Loss: 7.957103032030233e-11\n",
      "Epoch 820/1000, Loss: 1.2458492570921464e-11\n",
      "Epoch 830/1000, Loss: 2.3800530990492064e-11\n",
      "Epoch 840/1000, Loss: 2.6664018215605267e-11\n",
      "Epoch 850/1000, Loss: 7.677859736876513e-11\n",
      "Epoch 860/1000, Loss: 3.903811995886741e-11\n",
      "Epoch 870/1000, Loss: 4.299229028337237e-11\n",
      "Epoch 880/1000, Loss: 1.7775128591246414e-11\n",
      "Epoch 890/1000, Loss: 5.31246296953114e-11\n",
      "Epoch 900/1000, Loss: 4.9563034232313896e-11\n",
      "Epoch 910/1000, Loss: 1.2065917709414009e-11\n",
      "Epoch 920/1000, Loss: 3.6517469603758457e-11\n",
      "Epoch 930/1000, Loss: 3.4737560050679406e-11\n",
      "Epoch 940/1000, Loss: 1.1303226410408485e-10\n",
      "Epoch 950/1000, Loss: 1.291100698574965e-10\n",
      "Epoch 960/1000, Loss: 5.2595275357170124e-11\n",
      "Epoch 970/1000, Loss: 1.0958613183564836e-10\n",
      "Epoch 980/1000, Loss: 3.895381794905006e-10\n",
      "Epoch 990/1000, Loss: 1.0175772724441146e-10\n",
      "Epoch 1000/1000, Loss: 2.3005332361325515e-10\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(batch_tensor)  # shape: (16, 1)\n",
    "    outputs = outputs * ahi_std + ahi_mean\n",
    "    loss = criterion(outputs, ahi_labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd14139f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "model = OxiNetCNN()\n",
    "ahi_pred = model(batch_tensor)\n",
    "\n",
    "ahi_pred = ahi_pred * ahi_std + ahi_mean\n",
    "\n",
    "print(ahi_pred.shape)  # Expected: torch.Size([16, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1385257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "print(torch.isnan(batch_tensor).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2013394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.866629</td>\n",
       "      <td>4.314248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.907532</td>\n",
       "      <td>31.318682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.766327</td>\n",
       "      <td>8.870293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.677034</td>\n",
       "      <td>2.990033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.629208</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.005559</td>\n",
       "      <td>5.426357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.819983</td>\n",
       "      <td>15.338346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.597886</td>\n",
       "      <td>1.432836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.550468</td>\n",
       "      <td>29.189190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.793631</td>\n",
       "      <td>1.299639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.873044</td>\n",
       "      <td>5.652759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.775097</td>\n",
       "      <td>25.617977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.657330</td>\n",
       "      <td>15.597485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.839231</td>\n",
       "      <td>21.551020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.708159</td>\n",
       "      <td>27.729084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.684862</td>\n",
       "      <td>7.836735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred       true\n",
       "0   13.866629   4.314248\n",
       "1   13.907532  31.318682\n",
       "2   13.766327   8.870293\n",
       "3   13.677034   2.990033\n",
       "4   13.629208   6.000000\n",
       "5   14.005559   5.426357\n",
       "6   13.819983  15.338346\n",
       "7   13.597886   1.432836\n",
       "8   13.550468  29.189190\n",
       "9   13.793631   1.299639\n",
       "10  13.873044   5.652759\n",
       "11  13.775097  25.617977\n",
       "12  13.657330  15.597485\n",
       "13  13.839231  21.551020\n",
       "14  13.708159  27.729084\n",
       "15  13.684862   7.836735"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"pred\": ahi_pred.squeeze(1).tolist(), \"true\": ahi_labels_np.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c0f4803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ccefcc46e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(ahi_pred.squeeze(1).tolist(), ahi_labels.squeeze(1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affca92b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langsmith",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
